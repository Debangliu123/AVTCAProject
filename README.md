# Audio-Visual Fusion with Temporal Convolutional Attention Network for Speech Separation  Model (AVTCA)
This repository  currently contains  a real-world speech separation result demo using AVTCA.

We obtained several real-world video recordings from YouTube containing mixed speech between two speakers to show the effectiveness of our separation model. The display results demos can be accessed through the following link: 

In this demo, videos 1 and 2 are both front-face recordings of the speaker, while the speakers in Videos 3,
4 and 5 have varying degrees of profile or facial movements.

[The demo in Google cloud disk](https://drive.google.com/file/d/1LAsx88BbygDJq4yPpexsW6nvt7NIrLas/view?usp=sharing)

[The demo in baidu cloud disk](https://pan.baidu.com/s/1siMz-kUNTlIdCZ5lv2TeDg)


## Citations ##
If you find our project useful in your research, please cite our work:
```bib
@ARTICLE{10683978,
  author={Liu, Debang and Zhang, Tianqi and Christensen, Mads Græsbøll and Yi, Chen and An, Zeliang},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Audio-Visual Fusion With Temporal Convolutional Attention Network for Speech Separation}, 
  year={2024},
  volume={32},
  pages={4647-4660},
  doi={10.1109/TASLP.2024.3463411}
}
```
